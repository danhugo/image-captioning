# image-captioning in your language
This project is to explore RNN and Transformer architectures through the image captioning task. Moreover, it becomes more interesting when approached in your language.

## Project Overview
### Objective
Detail the main objective of the project.

### Dataset
Describe the dataset used, its source, and any relevant details.

## Translation and Preprocessing
### Translation
Explain the process of translating captions and the tools used.

### Data Preprocessing
Outline the preprocessing steps for the dataset, including any data augmentation or normalization techniques.

## Model Architectures
### LSTM
Describe the LSTM architecture used for image captioning.

### Transformer
Describe the Transformer architecture used for image captioning.

## Training
### Training Setup
Provide details on the training setup, including hardware, software, and dependencies.

### Fine-Tuning on Translated Dataset
Explain the process of fine-tuning the models on the translated dataset.

## Evaluation
### Metrics
List the evaluation metrics used to assess model performance.

### Results
Present the results of the models, including any tables or graphs.

## Installation
Provide a step-by-step guide on how to install the project and its dependencies.

## Usage
### Running the Code
Instructions on how to run the training and evaluation scripts.

### Inference
Explain how to use the trained models for captioning new images.

## Experiments and Findings
### Comparative Analysis
Compare the performance of LSTM and Transformer models.

### Challenges
Discuss any challenges faced during the project.

### Future Work
Suggest potential improvements or future directions for the project.

## Contributing
Provide guidelines for contributing to the project.

## License
Detail the license under which the project is distributed.

## Acknowledgements
Acknowledge any contributors, advisors, or sources of inspiration.

## References
List any references or resources used in the project.